{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n",
    "## Nature\n",
    "### Yann LeCun, Yoshua Bengio & Geoffrey Hinton\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why this paper?\n",
    " After deciding to read research papers and write review of those, this is first research paper. There are many kinds of paper about specific method, architecture of CNN of others. But I just wanted to read and write about paper including all of the machine learning things. Hence, this research paper. By looking at history of machine learning, I thought it could be my foundation of what I will learn from now on. This paper starts by history of machine learning and processes until emergence of deep learning and explain about CNN and RNN. After that, it is finished with suggests what we have to do for ultimate goal of machine learning.\n",
    " \n",
    "#### why deep learning?\n",
    "##### Nonlinearity and efficient workflow\n",
    " There are two interesting things for me. The reason why deep learning has been developed and our final goal about machine learning. Especially, it is quite detail about the reason which is difficult to find in other common books. It has a lot of contents. First of all, the reason why deep learning has been developed is, obviously, limitation of conventional machine learning algorithms. Of course, there have been incredible progress due to conventional machine learning, like marketing, mail filtering, recommendation systems used in YOUTUBE or Google. But It is essential to management and transformation for features that requires lots of hand engineering and expertise in domain. What does this mean? In machine learning application, most of tasks consists of cycle of idea, code and experiment. Only if the circulation of this is fast, it will have more possibility of success in application. However, management for feature disturbs this circulation. Speed gets lower and Efficiency does. And there is another problem of it. Linearity. Algorithm which has linearity means they just can function only by carving simple boundary. It can’t classify more complicated structure or pattern of data. It is said in this research paper that as a good model, it has to suppress irrelevant feature and catch relevant data. That is why we need non-linearity model and why deep learning emerged.\n",
    "  \n",
    " Actually, neural network which is recently called as deep learning had been for a long time. But there were questions about algorithm to improve and calculation problem. In 1980s, it turned out that simple gradient descent algorithm with chain rule can solve algorithm problem and GPU did calculation problem in 2010s. And local optima problem was also revealed that it has very low probability. With many of multilayers which has non-linearity, we can approach to more complicated data and even to image and speech data. It’s just few years ago that overshadowed deep learning just draws enormous attention. By knowing this, I got it that why deep learning is so powerful and attractive for many researchers. With this knowledge, I think I can approach more wisely to application fields. Honestly, realizing deep learning by programming is not that difficult except detail tuning of model thanks to many handy frameworks such as TensorFlow and Keras. But we mustn’t be mistaken about deep learning. It feels like as long as there are deep learning model and data, I could make very meaningful results. It is not efficient way. It’s not like industrial engineering student. First thing we have to notice is insight of machine learning. In fact, there are many applications more fitting for other models like random forest, support vector machine and simple regression. I think this kind of knowledge is essential to solve present problems more wisely.\n",
    " \n",
    "#### Future of machine learning and deep learning\n",
    "##### Unsupervised learning and RCNN with End-to-End learning\n",
    " What about future of machine learning? In this paper, it suggests two proposals of improving machine learning technology. Importance of unsupervised learning and End-to-End learning for RCNN. First, unsupervised learning is more like learning process of human that can be regarded as advanced process. We don’t have to get labeled data to learn something. We just see data and make patterns simultaneously or even make label of it ourselves. There are not many books handling about unsupervised learning and what I’ve been learning is also focuses on supervised learning. But in this paper says, eventually, AI needs advanced unsupervised learning and it’s inevitable. It gave new insights on machine learning. I didn’t expect but there are also many research paper and research about unsupervised learning. And they particularly focus on GAN which is popular method of unsupervised learning. For instance, if it knows probability distribution, it could analyze all statistical features of data knowing its expected value and variance and make data arbitrarily according to given distribution, it can have similar data to original data. In other words, it can produce infinite data sharing probability distribution of original data. And there is DCGAN which is more powerful than normal GAN consisting of deepness and convolutional layer. Facebook’s Real-eye-opener applies this technology to manipulate pictures. It can produce fake pictures which look really natural. But there remains still problems like stability. Anyway, it’s quite interesting to me.\n",
    " \n",
    " And let’s move on to RCNN with End-to-End, combination of RNN and CNN. It sounds really theoretical when I saw this word in this paper, but this is also promising method of deep learning. When I took a lecture of deeplearning.ai, professor Andrew said it is very advanced type of neural network and it has some limitation for now. In addition, it combines RNN and CNN for that advanced type of neural network. RCNN features that all weights are shared and it has architecture which has CNN without fully connected and RNN. It can learn whole thing at once (end-to-end), handle time series data, and make compact model more efficiently and doesn’t have limitation vocabulary. It is already proved that its generality and advanced performance by OMR (Optical Music Recognition).What it means by that?  All things I’ve seen in this paper, especially future of machine learning, is pretty difficult to understand. But I’ve got to stack these knowledges continuously to get used to it. I am quite certain that it would make me more sensible when it comes to machine learning. I think I am in the middle of learning basic of machine learning. After few years, after I experience practice problem, then there is going to be sometime that I have to make a decision for which domain or which part of the machine learning I will study. This is why I started to read research paper and to reduce the gab between bachelor and master. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
